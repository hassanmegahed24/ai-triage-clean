AI-Triage-Homie Project Methodology
===================================

Purpose
-------
AI-Triage-Homie is a doctor-supervised voice intake assistant. It listens to the patient, gathers structured data, and—only when asked—surfaces live notes and a SOAP draft to the supervising physician. This document compiles the end-to-end methodology, covering project ideology, system architecture, chronological development, reasoning behind each change, and the operational flow required to reproduce the current solution.

Vision & Ideology
-----------------
- **Doctor-in-the-loop**: The agent never acts autonomously; every critical decision is deferred to the supervising physician.
- **Conversational safety**: It asks one question at a time, acknowledges interruptions, and respects physician barge-in.
- **Transparent tooling**: Working notes and SOAP drafts are generated by “mini-agent” tool calls so the clinician can audit and control every output.
- **Demo-ready flow**: For presentations, the experience must be predictable—clean conversation, no unexplained pauses, and immediate SOAP preview when the doctor requests it.

System Architecture
-------------------
```
Patient ↔ Frontend (React) ↔ Backend (FastAPI WebSocket) ↔ OpenAI Realtime API
                                              ↕
                                        Tool Handlers
                                              ↕
                                      Session Storage / DB stubs
```

- **Frontend (AI-Triage-Homie/Downloads)**  
  * `wsVoiceClient` establishes a WebSocket to our backend, streams microphone audio, plays model audio, and captures realtime events (`session.id`, `ui.*`, etc.).  
  * `PatientDetail.jsx` hosts the clinician workspace: connect/mic controls, live notes card, SOAP preview, and tool-call utilities (e.g., “Ask agent to revise”).
  * Session storage caches SOAP drafts so the `/soap-note` route can display the latest output in a dedicated tab.

- **Backend (AI-Triage-Homie-main)**  
  * `realtime_ws.py` bridges the browser and OpenAI Realtime: forwards audio/text, handles tool-call argument streaming, injects session IDs, and fans out UI events.  
  * `realtime_tool_handlers.py` executes `save_observation` (persist working notes) and `finalize_soap` (call reasoning client, stash SOAP).  
  * `/routes/summary.py`, `/routes/db.py`, and other REST endpoints serve additional data: patient feedback, snapshots, and manual note updates.

- **Prompt Suite**  
  * `realtime_voice_intake.md` defines the agent’s persona, clinical priorities, turn-by-turn style, tool usage rules, and doctor approval logic.  
  * `summary_finalize.user.txt` / `summary_reply.system.txt` guide the reasoning client when `finalize_soap` runs.

Conversation & Tool Flow
------------------------
1. Browser connects to `/realtime/ws`; backend assigns a UUID session id and opens an upstream WS to OpenAI Realtime.
2. Agent receives the master prompt and begins intake. Audio deltas stream both ways.
3. During intake, the agent keeps internal `working_notes`. When it needs to show notes (or the doctor asks), it calls `save_observation` → backend stores normalized text → backend emits `ui.observation.preview`.
4. When doctor approval is granted (“show me the SOAP”), the agent acknowledges, calls `save_observation`, emits “saved,” then calls `finalize_soap`. The backend runs the reasoning client, caches the SOAP, emits `ui.soap.preview`, and our frontend updates both panels.
5. Optional revisions: clinician can edit notes manually via PUT `/realtime/live-notes` or ask the agent to “revise,” which triggers another save/finalize cycle.

Chronological Development Log
-----------------------------
### 1. Mini-Agent Integration (Backend Foundations)
- Registered `save_observation` and `finalize_soap` tools with OpenAI session (`realtime_ws.py`).
- Created buffers for streaming tool arguments so multi-part payloads reassemble before invoking handlers.
- Ensured tool handlers (`realtime_tool_handlers.py`) return structured JSON with `ok`, `message`, and payload fields (`observation`, `soap`).
- Normalized observation text for UI display and implemented session-level flags (`SESSION_FLAGS`) to prevent finalize without a recent save.

### 2. Realtime Prompt Engineering (First Iteration)
- Authored the initial `realtime_voice_intake.md` covering role, safety, clinical priorities, and tool usage.
- Established “one question per turn” and “doctor hears everything” principles.
- Introduced barge handling: agent must halt immediately when the doctor interrupts.
- Outlined working-notes format (CC, HPI, etc.) to keep live observation structured.

### 3. Barge / Silence Fixes
- Added instructions in the prompt to acknowledge patient interruptions and resume with a targeted question.
- Tuned backend playback cancellation logic so `response.cancel` swallows residual audio for ~600ms (prevents agent talking over patient).
- Confirmed audio queue drains correctly (`wsVoiceClient.js` playback handlers).

### 4. SOAP Preview Visibility Work
- Initial problem: model claimed to use tools but UI remained blank.  
  Diagnostics: looked for `"type":"tool.output"` in Realtime stream, noticed calls missing or failing.  
  Resolution:  
    * Backend started emitting `ui.observation.preview` / `ui.soap.preview` events after handler success.  
    * Frontend subscribed to those events and updated state.  
    * Session storage mirrored SOAP payloads so `/soap-note` route could load them.

### 5. Approval Gate Rewrites
- Early versions made the agent freeze after asking for approval. Iterative prompt changes ensured it:
  * Keeps questioning the patient while approval is pending.
  * Only reminds the doctor every couple of turns with varied phrasing.
  * Responds to short answers (e.g., “5/10 pain”) with clarifiers before approaching the doctor.
  * Speaks its conclusions or questions directly; no silent waiting.

### 6. Frontend Tool-ID Hygiene
- “Ask agent to revise” initially reused stale `tool_call_id`s, causing `invalid_tool_call_id`.  
  Fix: `extractToolCallIdFromEvent` captures the latest tool call per session; UI button stays disabled until a valid call is present.  
  Hangup clears IDs to avoid cross-session pollution.

### 7. Demo-Oriented Simplification
- Prompt now mandates a single save→finalize sequence whenever the doctor asks for SOAP preview—ensuring both Live Notes and SOAP page update instantly.
- Agent explicitly narrates “On it—saving now… saved… SOAP ready, doctor,” giving the presenter a predictable moment to cut video or switch tabs.
- Optional: doctor can request edits; agent repeats the sequence only on request to avoid redundant SOAP churn.

Frontend Implementation Details
-------------------------------
- **Voice Workspace UI (`PatientDetail.jsx`)**
  * Connect → Start Mic → Stop & Ask → Send Text → Hang Up controls.
  * Status banner with session id snippet for debugging.
  * Live Notes card with edit/save controls (manual doctor edits stay optional).
  * SOAP preview card auto-opens when backend emits `ui.soap.preview`.  
  * Last event log (JSON) visible for quick inspection during testing.

- **Browser Storage**  
  * `persistSoapPreview` saves SOAP + observation + patient metadata per session.
  * `/soap-note/:pid` page reads session storage to render the latest draft for print/share.

- **Dashboard (`src/pages/Dashboard.jsx`)**
  * Fetches `/db/patient_feedback?limit=10` to populate cards.  
  * Fallback “Sarah Johnson” card when no data found, ensuring demos never show blank states.

Backend Implementation Details
------------------------------
- `realtime_ws.py` initial session update sets:
  * Modalities (`["text","audio"]`), voice, PCM formats.
  * Turn detection thresholds (server VAD) to avoid overlap.
  * Temperature 0.6 for balanced responses.
  * Tool definitions with JSON schema.
  * Master prompt text (3000+ characters).
- Tool handler responses propagate to browser via `browser_ws.send_text`. If UI send fails, logs error but doesn’t block conversation.
- REST endpoints:
  * `/realtime/live-notes` GET returns observation + cached SOAP.
  * `/realtime/live-notes` PUT allows clinician manual edits.
  * `/db/patient_feedback` accepts `ymd` and `limit`, returning chosen date entries first, then latest overall.
  * `/summary/finalize` orchestrates reasoning client finalize when session is closed via the web app (outside realtime flow).

Prompt Design Rationale
-----------------------
- **Role clarity**: agent repeatedly reminded it works under physician supervision; prevents autonomous advice.
- **Structured data capture**: working notes enforce SOAP-friendly structure even before finalization.
- **Doctor gate**: agent must ask permission before drafting SOAP; ensures doctor remains in control.
- **Live confirmation**: spoken acknowledgments let the doctor know when tools run, aligning audio with UI changes.
- **Flexibility for Q&A**: agent responds to doctor’s reasoning questions immediately, ensuring dialogues don’t stall.
- **Demo tweaks**: for presentation, observation save is bundled with SOAP finalization so a single request populates everything.

Testing & Validation
--------------------
- **Realtime WS inspector** (Chrome DevTools → Network → WS) used to confirm `tool.call`, `tool.output`, `ui.*` events.
- **Backend logs**: `[TOOLS]` lines verify argument ingestion, handler success, and tool output payloads.
- **Manual smoke tests**:  
  1. Run through sample conversation (back pain scenario).  
  2. Confirm live notes update when agent says “saved.”  
  3. Check `/soap-note` tab opens automatically with JSON from session storage.  
  4. Test “Ask agent to revise” only fires when tool call ID is present.  
  5. Disconnect/reconnect cycle to ensure state resets cleanly.

Operational Runbook
-------------------
1. **Backend**: `cd AI-Triage-Homie-main && uvicorn app.main:app --reload`  
   Verify startup logs show prompt length and no errors.
2. **Frontend**: `cd ~/Downloads/AI-Triage-Homie && npm start`  
   Ensure `.env` has `REACT_APP_API_BASE` pointing to backend (defaults to `http://localhost:8000`).
3. **Voice Session**:  
   * PatientDetail → `Start` → `Voice Record`.  
   * `Connect` → wait for status `connected`.  
   * `Start Mic` to begin intake.  
   * Conduct conversation per demo script.  
   * When ready, doctor says “Yes, show me the SOAP notes.”  
   * Observe agent performing save→finalize with spoken confirmations.
4. **Optional doctor edit**: use the Live Notes textarea or ask the agent for adjustments; rerun save→finalize on request.
5. **Hang Up**: click `Hang Up` to reset session and prepare for next take.

Reference Demo Script
---------------------
1. Patient: “My lower back has been aching since last Tuesday.”  
2. Agent: collects onset details.  
3. Patient: “It’s around a 6 out of 10; worse if I stand too long.”  
4. Agent: checks red flags, meds, function impact.  
5. Patient provides clarifiers (no numbness, took ibuprofen).  
6. Agent: “Doctor, I have the essentials. Would you like me to draft the SOAP notes now?”  
7. Doctor: “Yes, show me the SOAP notes.”  
8. Agent: “On it—saving now… saved… SOAP ready, doctor.” → UI panels populate.  
9. Doctor: optional follow-up (“Note gentle stretching.”) → agent acknowledges and offers to update.

Key Lessons Learned
-------------------
- Tool outputs must be echoed to both OpenAI and the browser; otherwise the model thinks work is done while the UI remains blank.
- Prompt microcopy dramatically affects flow: even a stray “wait for approval” caused multi-second freezes after short answers.
- Tracking tool-call IDs client-side is essential when providing manual override buttons; stale IDs cause irrecoverable `invalid_tool_call_id` errors.
- For demos, bundling observation + SOAP finalization yields predictable results, but production should keep them separable so doctors can preview notes without triggering a SOAP draft.

Future Enhancements
-------------------
- Add automated integration tests simulating the WS exchange (pytest + websockets) to guard against regressions in tool routing.
- Provide a visual indicator in the UI when the agent is waiting for doctor approval vs. actively interviewing.
- Implement a prompt “profile switch” so demo-mode shortcuts (auto finalize) can be toggled off for real deployments.
- Expand telemetry (structured logs or analytics) to capture conversation metrics, tool latencies, and doctor interactions for future tuning.
